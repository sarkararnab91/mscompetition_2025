{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3c581b5-f0d4-495f-8b82-e688a4bd9237",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "from tqdm import tqdm\n",
    "import sklearn\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer, SimpleImputer\n",
    "from sklearn.linear_model import LassoCV, BayesianRidge, LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, RobustScaler, MinMaxScaler\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold, StratifiedKFold, GridSearchCV\n",
    "from sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier\n",
    "from sklearn.metrics import f1_score, roc_auc_score, brier_score_loss\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "sklearn.set_config(enable_metadata_routing=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0bff05f0-d063-4bfa-be11-774bd1a4798e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import heavy file\n",
    "connectome = pd.read_csv('./TRAIN_NEW/TRAIN_FUNCTIONAL_CONNECTOME_MATRICES_new_36P_Pearson.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ae42f37-8547-4653-ad53-227a32317f85",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basic_Demos_Enroll_Year False\n",
      "Basic_Demos_Study_Site False\n",
      "PreInt_Demos_Fam_Child_Ethnicity True\n",
      "PreInt_Demos_Fam_Child_Race True\n",
      "MRI_Track_Scan_Location True\n",
      "Barratt_Barratt_P1_Edu True\n",
      "Barratt_Barratt_P1_Occ True\n",
      "Barratt_Barratt_P2_Edu True\n",
      "Barratt_Barratt_P2_Occ True\n"
     ]
    }
   ],
   "source": [
    "SEED = 42\n",
    "REPEATS = 5\n",
    "FOLDS = 5\n",
    "\n",
    "# Import Data \n",
    "# Train\n",
    "quantitative_metadata_train = pd.read_excel(\"./TRAIN_NEW/TRAIN_QUANTITATIVE_METADATA_new.xlsx\")\n",
    "categorical_metadata_train = pd.read_excel(\"./TRAIN_NEW/TRAIN_CATEGORICAL_METADATA_new.xlsx\")\n",
    "training_solutions = pd.read_excel(\"./TRAIN_NEW/TRAINING_SOLUTIONS.xlsx\")\n",
    "\n",
    "quantitative_metadata_train = quantitative_metadata_train.sort_values(by='participant_id')\n",
    "categorical_metadata_train = categorical_metadata_train.sort_values(by='participant_id')\n",
    "training_solutions  = training_solutions.sort_values(by='participant_id')\n",
    "\n",
    "# Test\n",
    "quantitative_metadata_test = pd.read_excel(\"./TEST/TEST_QUANTITATIVE_METADATA.xlsx\")\n",
    "categorical_metadata_test = pd.read_excel(\"./TEST/TEST_CATEGORICAL.xlsx\")\n",
    "\n",
    "quantitative_metadata_test = quantitative_metadata_test.sort_values(by='participant_id')\n",
    "categorical_metadata_test = categorical_metadata_test.sort_values(by='participant_id')\n",
    "\n",
    "#Dictionary\n",
    "data_dictionary = pd.read_excel('./Data Dictionary.xlsx', sheet_name=None)['Dictionary']\n",
    "\n",
    "#Select Columns which have consistent train test data\n",
    "drop_cat_cols = [] \n",
    "for cat in categorical_metadata_train.columns:\n",
    "    if cat not in ['participant_id']:\n",
    "        if False == np.all(np.isin(categorical_metadata_test[cat].dropna().unique(), categorical_metadata_train[cat].dropna().unique())):\n",
    "            drop_cat_cols.append(cat)\n",
    "        print(cat,np.all(np.isin(\n",
    "                            categorical_metadata_test[cat].dropna().unique(), \n",
    "                            categorical_metadata_train[cat].dropna().unique()\n",
    "                         )))\n",
    "\n",
    "#drop the columns\n",
    "categorical_metadata_train = categorical_metadata_train.drop(drop_cat_cols, axis=1)\n",
    "categorical_metadata_test = categorical_metadata_test.drop(drop_cat_cols, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bcbe8f52-56f6-4aa1-9753-47084c0f2fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Separate features and target\n",
    "quantitative_features_train = quantitative_metadata_train.drop(columns=['participant_id'])\n",
    "categorical_features_train = categorical_metadata_train.drop(columns=['participant_id'])\n",
    "quantitative_features_test = quantitative_metadata_test.drop(columns=['participant_id'])\n",
    "categorical_features_test = categorical_metadata_test.drop(columns=['participant_id'])\n",
    "\n",
    "# Column names\n",
    "quantitative_cols = quantitative_features_train.columns.tolist()\n",
    "categorical_cols = categorical_features_train.columns.tolist()\n",
    "\n",
    "# Build column transformer with imputation, scaling, and encoding\n",
    "numeric_pipeline = Pipeline([\n",
    "    ('imputer', IterativeImputer(estimator=BayesianRidge(), max_iter=50, random_state=SEED)),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('encoder', OneHotEncoder(drop='first', sparse_output=False))\n",
    "])\n",
    "\n",
    "# Full preprocessor\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', numeric_pipeline, quantitative_cols),\n",
    "    ('cat', categorical_pipeline, categorical_cols)\n",
    "])\n",
    "\n",
    "# Combine all features\n",
    "combined_features_train = pd.concat([quantitative_features_train, categorical_features_train], axis=1)\n",
    "combined_features_test = pd.concat([quantitative_features_test, categorical_features_test], axis=1)\n",
    "\n",
    "train_fe = combined_features_train.copy()\n",
    "test_fe = combined_features_test.copy()\n",
    "\n",
    "for df in [train_fe, test_fe]:\n",
    "    df['log_age'] = np.log1p(df['MRI_Track_Age_at_Scan'])\n",
    "\n",
    "bins = [0, 8, 10, 12, 14, 18]\n",
    "labels_age = ['<8', '8-10', '10-12', '12-14', '14-18']\n",
    "for df in [train_fe, test_fe]:\n",
    "    df['age_group'] = pd.cut(df['MRI_Track_Age_at_Scan'], bins=bins, labels=labels_age)\n",
    "    df['age_group'] = df['age_group'].cat.codes  # convert to numeric\n",
    "\n",
    "for df in [train_fe, test_fe]:\n",
    "    df['hyper_prosocial_ratio'] = df['SDQ_SDQ_Hyperactivity'] / (df['SDQ_SDQ_Prosocial'] + 0.01)\n",
    "    df['conduct_emotion_ratio'] = df['SDQ_SDQ_Conduct_Problems'] / (df['SDQ_SDQ_Emotional_Problems'] + 0.01)\n",
    "    df['external_internal_ratio'] = df['SDQ_SDQ_Externalizing'] / (df['SDQ_SDQ_Internalizing'] + 0.01)\n",
    "\n",
    "for df in [train_fe, test_fe]:\n",
    "    df['parent_edu_avg'] = (df['Barratt_Barratt_P1_Edu'] + df['Barratt_Barratt_P2_Edu']) / 2\n",
    "    df['parent_edu_diff'] = np.abs(df['Barratt_Barratt_P1_Edu'] - df['Barratt_Barratt_P2_Edu'])\n",
    "\n",
    "combined_features_train = train_fe.copy()\n",
    "combined_features_test = test_fe.copy()\n",
    "\n",
    "categorical_cols.extend(['age_group'])\n",
    "quantitative_cols.extend(['parent_edu_diff','parent_edu_avg','external_internal_ratio','conduct_emotion_ratio','hyper_prosocial_ratio','log_age'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "97ce3739-56a7-407f-921d-d7f098537f9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EHQ_EHQ_Total</th>\n",
       "      <th>ColorVision_CV_Score</th>\n",
       "      <th>APQ_P_APQ_P_CP</th>\n",
       "      <th>APQ_P_APQ_P_ID</th>\n",
       "      <th>APQ_P_APQ_P_INV</th>\n",
       "      <th>APQ_P_APQ_P_OPD</th>\n",
       "      <th>APQ_P_APQ_P_PM</th>\n",
       "      <th>APQ_P_APQ_P_PP</th>\n",
       "      <th>SDQ_SDQ_Conduct_Problems</th>\n",
       "      <th>SDQ_SDQ_Difficulties_Total</th>\n",
       "      <th>...</th>\n",
       "      <th>Barratt_Barratt_P2_Occ_40.0</th>\n",
       "      <th>Barratt_Barratt_P2_Occ_45.0</th>\n",
       "      <th>age_group_0.0</th>\n",
       "      <th>age_group_1.0</th>\n",
       "      <th>age_group_2.0</th>\n",
       "      <th>age_group_3.0</th>\n",
       "      <th>age_group_4.0</th>\n",
       "      <th>participant_id</th>\n",
       "      <th>ADHD_Outcome</th>\n",
       "      <th>Sex_F</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.818649</td>\n",
       "      <td>-0.200432</td>\n",
       "      <td>-0.619974</td>\n",
       "      <td>0.466855</td>\n",
       "      <td>0.871365</td>\n",
       "      <td>-1.195780</td>\n",
       "      <td>0.676349</td>\n",
       "      <td>0.492205</td>\n",
       "      <td>0.459264</td>\n",
       "      <td>0.737480</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>00aIpNTbG5uh</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.662351</td>\n",
       "      <td>0.277619</td>\n",
       "      <td>-0.619974</td>\n",
       "      <td>-0.372214</td>\n",
       "      <td>-0.984879</td>\n",
       "      <td>2.118612</td>\n",
       "      <td>2.233865</td>\n",
       "      <td>1.479493</td>\n",
       "      <td>1.451999</td>\n",
       "      <td>1.199700</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>00fV0OyyoLfw</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.549121</td>\n",
       "      <td>0.277619</td>\n",
       "      <td>-0.619974</td>\n",
       "      <td>2.144992</td>\n",
       "      <td>-0.572380</td>\n",
       "      <td>0.009453</td>\n",
       "      <td>1.844486</td>\n",
       "      <td>0.821301</td>\n",
       "      <td>0.459264</td>\n",
       "      <td>1.815994</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>04X1eiS79T4B</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.683986</td>\n",
       "      <td>0.277619</td>\n",
       "      <td>-0.619974</td>\n",
       "      <td>-0.651903</td>\n",
       "      <td>0.458866</td>\n",
       "      <td>-0.894472</td>\n",
       "      <td>0.676349</td>\n",
       "      <td>0.821301</td>\n",
       "      <td>-1.029839</td>\n",
       "      <td>-1.111402</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>05ocQutkURd6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.203320</td>\n",
       "      <td>0.277619</td>\n",
       "      <td>3.157463</td>\n",
       "      <td>-0.372214</td>\n",
       "      <td>-0.984879</td>\n",
       "      <td>1.214687</td>\n",
       "      <td>-0.881168</td>\n",
       "      <td>-0.495084</td>\n",
       "      <td>1.948367</td>\n",
       "      <td>1.661920</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>06YUNBA9ZRLq</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 77 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   EHQ_EHQ_Total  ColorVision_CV_Score  APQ_P_APQ_P_CP  APQ_P_APQ_P_ID  \\\n",
       "0       0.818649             -0.200432       -0.619974        0.466855   \n",
       "1       0.662351              0.277619       -0.619974       -0.372214   \n",
       "2       0.549121              0.277619       -0.619974        2.144992   \n",
       "3       0.683986              0.277619       -0.619974       -0.651903   \n",
       "4      -1.203320              0.277619        3.157463       -0.372214   \n",
       "\n",
       "   APQ_P_APQ_P_INV  APQ_P_APQ_P_OPD  APQ_P_APQ_P_PM  APQ_P_APQ_P_PP  \\\n",
       "0         0.871365        -1.195780        0.676349        0.492205   \n",
       "1        -0.984879         2.118612        2.233865        1.479493   \n",
       "2        -0.572380         0.009453        1.844486        0.821301   \n",
       "3         0.458866        -0.894472        0.676349        0.821301   \n",
       "4        -0.984879         1.214687       -0.881168       -0.495084   \n",
       "\n",
       "   SDQ_SDQ_Conduct_Problems  SDQ_SDQ_Difficulties_Total  ...  \\\n",
       "0                  0.459264                    0.737480  ...   \n",
       "1                  1.451999                    1.199700  ...   \n",
       "2                  0.459264                    1.815994  ...   \n",
       "3                 -1.029839                   -1.111402  ...   \n",
       "4                  1.948367                    1.661920  ...   \n",
       "\n",
       "   Barratt_Barratt_P2_Occ_40.0  Barratt_Barratt_P2_Occ_45.0  age_group_0.0  \\\n",
       "0                          0.0                          1.0            0.0   \n",
       "1                          0.0                          1.0            0.0   \n",
       "2                          0.0                          1.0            0.0   \n",
       "3                          0.0                          0.0            0.0   \n",
       "4                          0.0                          1.0            1.0   \n",
       "\n",
       "   age_group_1.0  age_group_2.0  age_group_3.0  age_group_4.0  participant_id  \\\n",
       "0            0.0            0.0            0.0            1.0    00aIpNTbG5uh   \n",
       "1            0.0            0.0            0.0            0.0    00fV0OyyoLfw   \n",
       "2            0.0            0.0            1.0            0.0    04X1eiS79T4B   \n",
       "3            1.0            0.0            0.0            0.0    05ocQutkURd6   \n",
       "4            0.0            0.0            0.0            0.0    06YUNBA9ZRLq   \n",
       "\n",
       "   ADHD_Outcome  Sex_F  \n",
       "0             1      0  \n",
       "1             1      0  \n",
       "2             0      1  \n",
       "3             0      1  \n",
       "4             1      0  \n",
       "\n",
       "[5 rows x 77 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Apply transformations\n",
    "processed_array_train = preprocessor.fit_transform(combined_features_train)\n",
    "processed_array_test = preprocessor.transform(combined_features_test)\n",
    "\n",
    "# Get encoded feature names\n",
    "encoded_cat_cols = preprocessor.named_transformers_['cat']['encoder'].get_feature_names_out(categorical_cols)\n",
    "final_feature_names = quantitative_cols + list(encoded_cat_cols)\n",
    "\n",
    "# Create DataFrame\n",
    "processed_df_train = pd.DataFrame(processed_array_train, columns=final_feature_names)\n",
    "processed_df_test = pd.DataFrame(processed_array_test, columns=final_feature_names)\n",
    "\n",
    "processed_df_train['participant_id'] = quantitative_metadata_train['participant_id']\n",
    "processed_df_test['participant_id'] = quantitative_metadata_test['participant_id']\n",
    "\n",
    "train_combined = pd.merge(processed_df_train, training_solutions, on='participant_id', how='inner')\n",
    "test_combined = processed_df_test\n",
    "display(train_combined.head())\n",
    "#---------------------------------------------------------------------\n",
    "y_adhd = train_combined[\"ADHD_Outcome\"]\n",
    "y_sex = train_combined[\"Sex_F\"]\n",
    "#---------------------------------------------------------------------\n",
    "combinations = train_combined[\"ADHD_Outcome\"].astype(str) + train_combined[\"Sex_F\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0ca24a7a-bf6c-46a8-a3c7-15bad09f5ec6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "features_sex_old = [\n",
    "       'EHQ_EHQ_Total', 'ColorVision_CV_Score', 'APQ_P_APQ_P_CP',\n",
    "       'APQ_P_APQ_P_ID', 'APQ_P_APQ_P_INV', 'APQ_P_APQ_P_OPD',\n",
    "       'APQ_P_APQ_P_PM', 'APQ_P_APQ_P_PP', 'SDQ_SDQ_Conduct_Problems',\n",
    "       'SDQ_SDQ_Difficulties_Total', 'SDQ_SDQ_Emotional_Problems',\n",
    "       'SDQ_SDQ_Externalizing', 'SDQ_SDQ_Generating_Impact',\n",
    "       'SDQ_SDQ_Hyperactivity', 'SDQ_SDQ_Internalizing',\n",
    "       'SDQ_SDQ_Peer_Problems', 'SDQ_SDQ_Prosocial', 'MRI_Track_Age_at_Scan',\n",
    "       'Barratt_Barratt_P1_Edu', 'Barratt_Barratt_P2_Edu', 'log_age', 'age_group',\n",
    "       'hyper_prosocial_ratio', 'conduct_emotion_ratio',\n",
    "       'external_internal_ratio',\n",
    "       'parent_edu_avg', 'parent_edu_diff'\n",
    "]\n",
    "\n",
    "features_sex = [s for s in train_combined.columns if any(sub in s for sub in features_sex_old)]\n",
    "\n",
    "\n",
    "features_adhd_old = [\n",
    "       'EHQ_EHQ_Total', 'ColorVision_CV_Score', 'APQ_P_APQ_P_CP',\n",
    "       'APQ_P_APQ_P_ID', 'APQ_P_APQ_P_INV', 'APQ_P_APQ_P_OPD',\n",
    "       'APQ_P_APQ_P_PM', 'APQ_P_APQ_P_PP', 'SDQ_SDQ_Conduct_Problems',\n",
    "       'SDQ_SDQ_Difficulties_Total', 'SDQ_SDQ_Emotional_Problems',\n",
    "       'SDQ_SDQ_Externalizing', 'SDQ_SDQ_Generating_Impact',\n",
    "       'SDQ_SDQ_Hyperactivity', 'SDQ_SDQ_Internalizing',\n",
    "       'SDQ_SDQ_Peer_Problems', 'SDQ_SDQ_Prosocial', 'MRI_Track_Age_at_Scan',\n",
    "       'Barratt_Barratt_P1_Edu', 'Barratt_Barratt_P2_Edu', 'sex_proba',\n",
    "       'I_APQ_P_APQ_P_INV', 'I_APQ_P_APQ_P_PP', 'I_SDQ_SDQ_Hyperactivity',\n",
    "       'I_MRI_Track_Age_at_Scan', 'I_SDQ_SDQ_Generating_Impact', 'log_age', 'age_group',\n",
    "       'hyper_prosocial_ratio', 'conduct_emotion_ratio',\n",
    "       'external_internal_ratio',\n",
    "       'parent_edu_avg', 'parent_edu_diff'\n",
    "]\n",
    "\n",
    "features_adhd = [s for s in train_combined.columns if any(sub in s for sub in features_adhd_old)]\n",
    "\n",
    "\n",
    "interactions = [\n",
    "    \"APQ_P_APQ_P_INV\", \"APQ_P_APQ_P_PP\", \"SDQ_SDQ_Hyperactivity\",\n",
    "    \"MRI_Track_Age_at_Scan\", \"SDQ_SDQ_Generating_Impact\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e867e1e-b355-455b-97a6-92f3ba6fd5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_metrics(y_true, y_pred, weights, label=\"None\", thresh=0.5):\n",
    "    \"\"\"Evaluate predictions using Brier Score and F1 Score.\"\"\"\n",
    "    brier = brier_score_loss(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, (y_pred > thresh).astype(int), sample_weight=weights)\n",
    "    print(f\"{label} -> Brier Score: {brier:.4f}, F1: {f1:.4f}\")\n",
    "    return brier, f1\n",
    "\n",
    "#placeholder for results\n",
    "scores_sex = []\n",
    "scores_adhd = []\n",
    "\n",
    "sex_oof = np.zeros(len(y_sex))\n",
    "adhd_oof = np.zeros(len(y_adhd))\n",
    "\n",
    "t_sex = 0.3\n",
    "t_adhd = 0.4\n",
    "\n",
    "rskf = RepeatedStratifiedKFold(n_splits=FOLDS, n_repeats=REPEATS, random_state=SEED)\n",
    "skf = StratifiedKFold(n_splits=FOLDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1b47d319-b8c6-4a62-b136-72d5001b21a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define candidate models and their parameters (including XGBoost)\n",
    "params_xgb = {\n",
    "    'objective': 'binary:logistic',\n",
    "    'eval_metric': 'logloss',\n",
    "    # 'subsample': 0.8,\n",
    "    # 'colsample_bytree': 0.8,\n",
    "    'random_state': SEED\n",
    "}\n",
    "\n",
    "model_params = {\n",
    "    'logistic_regression': {\n",
    "        'model': LogisticRegression(solver='saga', max_iter=5000),\n",
    "        'params': {\n",
    "            'penalty': ['l1', 'l2'],\n",
    "            'C': [0.01, 0.1, 1, 10]\n",
    "        },\n",
    "        'weight_param': 'clf__sample_weight'\n",
    "    },\n",
    "    'svc': {\n",
    "        'model': SVC(probability=True),\n",
    "        'params': {\n",
    "            'C': [0.1, 1, 10],\n",
    "            'kernel': ['linear', 'rbf']\n",
    "        },\n",
    "        'weight_param': 'clf__sample_weight'\n",
    "    },\n",
    "    'random_forest': {\n",
    "        'model': RandomForestClassifier(),\n",
    "        'params': {\n",
    "            'n_estimators': [50, 100],\n",
    "            'max_depth': [5, 10, None]\n",
    "        },\n",
    "        'weight_param': 'clf__sample_weight'\n",
    "    },\n",
    "    'xgboost': {\n",
    "        'model': XGBClassifier(**params_xgb),\n",
    "        'params': {\n",
    "\n",
    "            'n_estimators': [300, 150, 50, 100],\n",
    "            'max_depth': [3,5],\n",
    "            'learning_rate': [0.03, 0.01, 0.07],\n",
    "            'subsample': [0.7,0.8, 1.0],\n",
    "            'colsample_bytree': [0.7,0.8, 1.0]\n",
    "        },\n",
    "        'weight_param': 'clf__sample_weight'\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "def GridSearch(X_grid, y_grid, sample_weights):\n",
    "    scores = []\n",
    "    # GridSearchCV for each model\n",
    "    for model_name, mp in model_params.items():\n",
    "        pipe = Pipeline([\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('clf', mp['model'])\n",
    "        ])\n",
    "\n",
    "        clf = GridSearchCV(\n",
    "            pipe,\n",
    "            {f'clf__{k}': v for k, v in mp['params'].items()},\n",
    "            cv=skf,\n",
    "            scoring='f1',\n",
    "            return_train_score=False\n",
    "        )\n",
    "        fit_params = {mp['weight_param']: sample_weights} if 'weight_param' in mp else {}\n",
    "        clf.fit(X_grid, y_grid, **fit_params)\n",
    "\n",
    "        scores.append({\n",
    "            'model': model_name,\n",
    "            'best_score': clf.best_score_,\n",
    "            'best_params': clf.best_params_,\n",
    "            'best_estimator': clf.best_estimator_\n",
    "        })\n",
    "\n",
    "    # Create DataFrame and select best\n",
    "    results_df = pd.DataFrame(scores)\n",
    "    results_df_sorted = results_df.sort_values(by='best_score', ascending=False).reset_index(drop=True)\n",
    "    best_model = results_df_sorted.loc[0, 'best_estimator']\n",
    "    print(f\"Best Model: {results_df_sorted.loc[0, 'model']}\")\n",
    "    print(f\"Best F1 Score: {results_df_sorted.loc[0, 'best_score']:.4f}\")\n",
    "    print(f\"Best Params: {results_df_sorted.loc[0, 'best_params']}\")\n",
    "\n",
    "    return best_model , results_df_sorted.loc[0, 'best_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b3f448dc-52c9-43d2-a801-73100886f35a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Fold 1 ===\n",
      "Best Model: logistic_regression\n",
      "Best F1 Score: 0.4728\n",
      "Best Params: {'clf__C': 10, 'clf__penalty': 'l2'}\n",
      "Sex_F -> Brier Score: 0.2401, F1: 0.5706\n",
      "Best Model: xgboost\n",
      "Best F1 Score: 0.8637\n",
      "Best Params: {'clf__colsample_bytree': 0.7, 'clf__learning_rate': 0.03, 'clf__max_depth': 3, 'clf__n_estimators': 100, 'clf__subsample': 1.0}\n",
      "Outcome ADHD -> Brier Score: 0.1253, F1: 0.8977\n",
      "\n",
      "=== Fold 2 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model: svc\n",
      "Best F1 Score: 0.4867\n",
      "Best Params: {'clf__C': 10, 'clf__kernel': 'linear'}\n",
      "Sex_F -> Brier Score: 0.2211, F1: 0.5696\n",
      "Best Model: xgboost\n",
      "Best F1 Score: 0.8676\n",
      "Best Params: {'clf__colsample_bytree': 0.7, 'clf__learning_rate': 0.07, 'clf__max_depth': 3, 'clf__n_estimators': 50, 'clf__subsample': 0.8}\n",
      "Outcome ADHD -> Brier Score: 0.1523, F1: 0.8802\n",
      "\n",
      "=== Fold 3 ===\n",
      "Best Model: logistic_regression\n",
      "Best F1 Score: 0.4615\n",
      "Best Params: {'clf__C': 0.1, 'clf__penalty': 'l1'}\n",
      "Sex_F -> Brier Score: 0.2298, F1: 0.6350\n",
      "Best Model: xgboost\n",
      "Best F1 Score: 0.8652\n",
      "Best Params: {'clf__colsample_bytree': 0.7, 'clf__learning_rate': 0.03, 'clf__max_depth': 3, 'clf__n_estimators': 100, 'clf__subsample': 0.8}\n",
      "Outcome ADHD -> Brier Score: 0.1519, F1: 0.8753\n",
      "\n",
      "=== Fold 4 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model: xgboost\n",
      "Best F1 Score: 0.4757\n",
      "Best Params: {'clf__colsample_bytree': 1.0, 'clf__learning_rate': 0.07, 'clf__max_depth': 3, 'clf__n_estimators': 50, 'clf__subsample': 0.7}\n",
      "Sex_F -> Brier Score: 0.2292, F1: 0.6069\n",
      "Best Model: xgboost\n",
      "Best F1 Score: 0.8730\n",
      "Best Params: {'clf__colsample_bytree': 0.8, 'clf__learning_rate': 0.07, 'clf__max_depth': 3, 'clf__n_estimators': 150, 'clf__subsample': 1.0}\n",
      "Outcome ADHD -> Brier Score: 0.1604, F1: 0.8722\n",
      "\n",
      "=== Fold 5 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model: svc\n",
      "Best F1 Score: 0.4376\n",
      "Best Params: {'clf__C': 1, 'clf__kernel': 'linear'}\n",
      "Sex_F -> Brier Score: 0.2105, F1: 0.6554\n",
      "Best Model: xgboost\n",
      "Best F1 Score: 0.8697\n",
      "Best Params: {'clf__colsample_bytree': 0.7, 'clf__learning_rate': 0.03, 'clf__max_depth': 5, 'clf__n_estimators': 100, 'clf__subsample': 0.8}\n",
      "Outcome ADHD -> Brier Score: 0.1566, F1: 0.8810\n",
      "\n",
      "=== Fold 6 ===\n",
      "Best Model: logistic_regression\n",
      "Best F1 Score: 0.4937\n",
      "Best Params: {'clf__C': 0.1, 'clf__penalty': 'l2'}\n",
      "Sex_F -> Brier Score: 0.2367, F1: 0.5940\n",
      "Best Model: xgboost\n",
      "Best F1 Score: 0.8613\n",
      "Best Params: {'clf__colsample_bytree': 1.0, 'clf__learning_rate': 0.03, 'clf__max_depth': 3, 'clf__n_estimators': 300, 'clf__subsample': 0.7}\n",
      "Outcome ADHD -> Brier Score: 0.1422, F1: 0.8856\n",
      "\n",
      "=== Fold 7 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model: svc\n",
      "Best F1 Score: 0.4812\n",
      "Best Params: {'clf__C': 1, 'clf__kernel': 'linear'}\n",
      "Sex_F -> Brier Score: 0.2193, F1: 0.6667\n",
      "Best Model: xgboost\n",
      "Best F1 Score: 0.8741\n",
      "Best Params: {'clf__colsample_bytree': 0.8, 'clf__learning_rate': 0.07, 'clf__max_depth': 3, 'clf__n_estimators': 50, 'clf__subsample': 0.8}\n",
      "Outcome ADHD -> Brier Score: 0.1636, F1: 0.8688\n",
      "\n",
      "=== Fold 8 ===\n",
      "Best Model: xgboost\n",
      "Best F1 Score: 0.4580\n",
      "Best Params: {'clf__colsample_bytree': 1.0, 'clf__learning_rate': 0.03, 'clf__max_depth': 3, 'clf__n_estimators': 150, 'clf__subsample': 0.7}\n",
      "Sex_F -> Brier Score: 0.2304, F1: 0.5846\n",
      "Best Model: xgboost\n",
      "Best F1 Score: 0.8697\n",
      "Best Params: {'clf__colsample_bytree': 0.7, 'clf__learning_rate': 0.01, 'clf__max_depth': 3, 'clf__n_estimators': 300, 'clf__subsample': 0.8}\n",
      "Outcome ADHD -> Brier Score: 0.1518, F1: 0.8755\n",
      "\n",
      "=== Fold 9 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model: svc\n",
      "Best F1 Score: 0.4670\n",
      "Best Params: {'clf__C': 0.1, 'clf__kernel': 'linear'}\n",
      "Sex_F -> Brier Score: 0.2183, F1: 0.5951\n",
      "Best Model: xgboost\n",
      "Best F1 Score: 0.8751\n",
      "Best Params: {'clf__colsample_bytree': 1.0, 'clf__learning_rate': 0.07, 'clf__max_depth': 5, 'clf__n_estimators': 50, 'clf__subsample': 1.0}\n",
      "Outcome ADHD -> Brier Score: 0.1627, F1: 0.8739\n",
      "\n",
      "=== Fold 10 ===\n",
      "Best Model: svc\n",
      "Best F1 Score: 0.4602\n",
      "Best Params: {'clf__C': 10, 'clf__kernel': 'linear'}\n",
      "Sex_F -> Brier Score: 0.2113, F1: 0.6313\n",
      "Best Model: xgboost\n",
      "Best F1 Score: 0.8602\n",
      "Best Params: {'clf__colsample_bytree': 1.0, 'clf__learning_rate': 0.01, 'clf__max_depth': 3, 'clf__n_estimators': 300, 'clf__subsample': 0.8}\n",
      "Outcome ADHD -> Brier Score: 0.1237, F1: 0.9071\n",
      "\n",
      "=== Fold 11 ===\n",
      "Best Model: logistic_regression\n",
      "Best F1 Score: 0.4538\n",
      "Best Params: {'clf__C': 1, 'clf__penalty': 'l2'}\n",
      "Sex_F -> Brier Score: 0.2235, F1: 0.6141\n",
      "Best Model: logistic_regression\n",
      "Best F1 Score: 0.8656\n",
      "Best Params: {'clf__C': 0.1, 'clf__penalty': 'l1'}\n",
      "Outcome ADHD -> Brier Score: 0.1438, F1: 0.8845\n",
      "\n",
      "=== Fold 12 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model: logistic_regression\n",
      "Best F1 Score: 0.4779\n",
      "Best Params: {'clf__C': 10, 'clf__penalty': 'l1'}\n",
      "Sex_F -> Brier Score: 0.2363, F1: 0.5956\n",
      "Best Model: xgboost\n",
      "Best F1 Score: 0.8686\n",
      "Best Params: {'clf__colsample_bytree': 0.8, 'clf__learning_rate': 0.03, 'clf__max_depth': 3, 'clf__n_estimators': 100, 'clf__subsample': 0.8}\n",
      "Outcome ADHD -> Brier Score: 0.1284, F1: 0.8879\n",
      "\n",
      "=== Fold 13 ===\n",
      "Best Model: xgboost\n",
      "Best F1 Score: 0.4888\n",
      "Best Params: {'clf__colsample_bytree': 1.0, 'clf__learning_rate': 0.07, 'clf__max_depth': 3, 'clf__n_estimators': 100, 'clf__subsample': 0.7}\n",
      "Sex_F -> Brier Score: 0.2316, F1: 0.6006\n",
      "Best Model: xgboost\n",
      "Best F1 Score: 0.8702\n",
      "Best Params: {'clf__colsample_bytree': 0.8, 'clf__learning_rate': 0.03, 'clf__max_depth': 3, 'clf__n_estimators': 50, 'clf__subsample': 1.0}\n",
      "Outcome ADHD -> Brier Score: 0.1695, F1: 0.8742\n",
      "\n",
      "=== Fold 14 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model: logistic_regression\n",
      "Best F1 Score: 0.4590\n",
      "Best Params: {'clf__C': 1, 'clf__penalty': 'l2'}\n",
      "Sex_F -> Brier Score: 0.2373, F1: 0.6227\n",
      "Best Model: xgboost\n",
      "Best F1 Score: 0.8601\n",
      "Best Params: {'clf__colsample_bytree': 0.7, 'clf__learning_rate': 0.03, 'clf__max_depth': 5, 'clf__n_estimators': 150, 'clf__subsample': 1.0}\n",
      "Outcome ADHD -> Brier Score: 0.1298, F1: 0.8966\n",
      "\n",
      "=== Fold 15 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model: logistic_regression\n",
      "Best F1 Score: 0.4904\n",
      "Best Params: {'clf__C': 10, 'clf__penalty': 'l1'}\n",
      "Sex_F -> Brier Score: 0.2262, F1: 0.6458\n",
      "Best Model: xgboost\n",
      "Best F1 Score: 0.8726\n",
      "Best Params: {'clf__colsample_bytree': 1.0, 'clf__learning_rate': 0.01, 'clf__max_depth': 3, 'clf__n_estimators': 300, 'clf__subsample': 0.7}\n",
      "Outcome ADHD -> Brier Score: 0.1525, F1: 0.8803\n",
      "\n",
      "=== Fold 16 ===\n",
      "Best Model: logistic_regression\n",
      "Best F1 Score: 0.4728\n",
      "Best Params: {'clf__C': 10, 'clf__penalty': 'l2'}\n",
      "Sex_F -> Brier Score: 0.2457, F1: 0.6171\n",
      "Best Model: xgboost\n",
      "Best F1 Score: 0.8750\n",
      "Best Params: {'clf__colsample_bytree': 0.8, 'clf__learning_rate': 0.03, 'clf__max_depth': 3, 'clf__n_estimators': 300, 'clf__subsample': 1.0}\n",
      "Outcome ADHD -> Brier Score: 0.1657, F1: 0.8632\n",
      "\n",
      "=== Fold 17 ===\n",
      "Best Model: svc\n",
      "Best F1 Score: 0.4550\n",
      "Best Params: {'clf__C': 10, 'clf__kernel': 'linear'}\n",
      "Sex_F -> Brier Score: 0.2167, F1: 0.6240\n",
      "Best Model: xgboost\n",
      "Best F1 Score: 0.8661\n",
      "Best Params: {'clf__colsample_bytree': 1.0, 'clf__learning_rate': 0.03, 'clf__max_depth': 3, 'clf__n_estimators': 150, 'clf__subsample': 0.8}\n",
      "Outcome ADHD -> Brier Score: 0.1462, F1: 0.8918\n",
      "\n",
      "=== Fold 18 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model: logistic_regression\n",
      "Best F1 Score: 0.4496\n",
      "Best Params: {'clf__C': 10, 'clf__penalty': 'l1'}\n",
      "Sex_F -> Brier Score: 0.2135, F1: 0.6335\n",
      "Best Model: xgboost\n",
      "Best F1 Score: 0.8656\n",
      "Best Params: {'clf__colsample_bytree': 0.7, 'clf__learning_rate': 0.01, 'clf__max_depth': 3, 'clf__n_estimators': 150, 'clf__subsample': 0.7}\n",
      "Outcome ADHD -> Brier Score: 0.1485, F1: 0.8815\n",
      "\n",
      "=== Fold 19 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model: logistic_regression\n",
      "Best F1 Score: 0.4847\n",
      "Best Params: {'clf__C': 1, 'clf__penalty': 'l2'}\n",
      "Sex_F -> Brier Score: 0.2389, F1: 0.6396\n",
      "Best Model: xgboost\n",
      "Best F1 Score: 0.8686\n",
      "Best Params: {'clf__colsample_bytree': 1.0, 'clf__learning_rate': 0.07, 'clf__max_depth': 5, 'clf__n_estimators': 50, 'clf__subsample': 1.0}\n",
      "Outcome ADHD -> Brier Score: 0.1518, F1: 0.8723\n",
      "\n",
      "=== Fold 20 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model: xgboost\n",
      "Best F1 Score: 0.4636\n",
      "Best Params: {'clf__colsample_bytree': 1.0, 'clf__learning_rate': 0.03, 'clf__max_depth': 3, 'clf__n_estimators': 150, 'clf__subsample': 0.7}\n",
      "Sex_F -> Brier Score: 0.2368, F1: 0.5722\n",
      "Best Model: xgboost\n",
      "Best F1 Score: 0.8607\n",
      "Best Params: {'clf__colsample_bytree': 0.8, 'clf__learning_rate': 0.07, 'clf__max_depth': 3, 'clf__n_estimators': 100, 'clf__subsample': 0.8}\n",
      "Outcome ADHD -> Brier Score: 0.1265, F1: 0.8918\n",
      "\n",
      "=== Fold 21 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model: logistic_regression\n",
      "Best F1 Score: 0.4875\n",
      "Best Params: {'clf__C': 10, 'clf__penalty': 'l2'}\n",
      "Sex_F -> Brier Score: 0.2272, F1: 0.6188\n",
      "Best Model: xgboost\n",
      "Best F1 Score: 0.8663\n",
      "Best Params: {'clf__colsample_bytree': 1.0, 'clf__learning_rate': 0.07, 'clf__max_depth': 3, 'clf__n_estimators': 50, 'clf__subsample': 1.0}\n",
      "Outcome ADHD -> Brier Score: 0.1427, F1: 0.8879\n",
      "\n",
      "=== Fold 22 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model: logistic_regression\n",
      "Best F1 Score: 0.4866\n",
      "Best Params: {'clf__C': 10, 'clf__penalty': 'l2'}\n",
      "Sex_F -> Brier Score: 0.2333, F1: 0.6075\n",
      "Best Model: xgboost\n",
      "Best F1 Score: 0.8662\n",
      "Best Params: {'clf__colsample_bytree': 1.0, 'clf__learning_rate': 0.07, 'clf__max_depth': 3, 'clf__n_estimators': 50, 'clf__subsample': 0.7}\n",
      "Outcome ADHD -> Brier Score: 0.1527, F1: 0.8774\n",
      "\n",
      "=== Fold 23 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model: svc\n",
      "Best F1 Score: 0.4868\n",
      "Best Params: {'clf__C': 10, 'clf__kernel': 'linear'}\n",
      "Sex_F -> Brier Score: 0.2185, F1: 0.6261\n",
      "Best Model: xgboost\n",
      "Best F1 Score: 0.8695\n",
      "Best Params: {'clf__colsample_bytree': 0.8, 'clf__learning_rate': 0.07, 'clf__max_depth': 3, 'clf__n_estimators': 50, 'clf__subsample': 1.0}\n",
      "Outcome ADHD -> Brier Score: 0.1485, F1: 0.8722\n",
      "\n",
      "=== Fold 24 ===\n",
      "Best Model: svc\n",
      "Best F1 Score: 0.4556\n",
      "Best Params: {'clf__C': 10, 'clf__kernel': 'linear'}\n",
      "Sex_F -> Brier Score: 0.2107, F1: 0.6185\n",
      "Best Model: xgboost\n",
      "Best F1 Score: 0.8636\n",
      "Best Params: {'clf__colsample_bytree': 0.7, 'clf__learning_rate': 0.03, 'clf__max_depth': 5, 'clf__n_estimators': 100, 'clf__subsample': 0.7}\n",
      "Outcome ADHD -> Brier Score: 0.1395, F1: 0.8950\n",
      "\n",
      "=== Fold 25 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model: logistic_regression\n",
      "Best F1 Score: 0.4655\n",
      "Best Params: {'clf__C': 0.1, 'clf__penalty': 'l2'}\n",
      "Sex_F -> Brier Score: 0.2328, F1: 0.6234\n",
      "Best Model: logistic_regression\n",
      "Best F1 Score: 0.8660\n",
      "Best Params: {'clf__C': 0.1, 'clf__penalty': 'l1'}\n",
      "Outcome ADHD -> Brier Score: 0.1540, F1: 0.8720\n",
      "\n",
      "=== CV Results ===\n",
      "Sex Mean Brier Score: 0.2270\n",
      "Sex Mean F1: 0.6147\n",
      "ADHD Mean Brier Score: 0.1476\n",
      "ADHD Mean F1: 0.8818\n"
     ]
    }
   ],
   "source": [
    "all_Bestmodels_sex = []\n",
    "all_Bestmodels_adhd = []\n",
    "scores_sex_gridcvs = []\n",
    "scores_adhd_gridcvs =[]\n",
    "scores_adhd = []\n",
    "scores_sex = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(rskf.split(train_combined, combinations), 1):\n",
    "    print(f\"\\n=== Fold {fold} ===\")\n",
    "\n",
    "    X_train, X_val = train_combined.iloc[train_idx].copy(), train_combined.iloc[val_idx].copy()\n",
    "    y_train_adhd, y_val_adhd = y_adhd.iloc[train_idx], y_adhd.iloc[val_idx]\n",
    "    y_train_sex, y_val_sex = y_sex.iloc[train_idx], y_sex.iloc[val_idx]\n",
    "    weights_train = np.where(combinations.iloc[train_idx]==\"11\", 2, 1)\n",
    "    weights = np.where(combinations.iloc[val_idx]==\"11\", 2, 1)\n",
    "\n",
    "    model_1, scores_sex_gridcv = GridSearch(X_train[features_sex], y_train_sex, weights_train)\n",
    "    # model_1.fit(X_train[features_sex], y_train_sex, sample_weight=weights_train)\n",
    "\n",
    "    all_Bestmodels_sex.append(model_1)\n",
    "    scores_sex_gridcvs.append(scores_sex_gridcv)\n",
    "\n",
    "    sex_train = model_1.predict_proba(X_train[features_sex])[:, 1]\n",
    "    sex_val = model_1.predict_proba(X_val[features_sex])[:, 1]\n",
    "    sex_oof[val_idx] += sex_val / REPEATS\n",
    "\n",
    "    sex_brier, sex_f1 = eval_metrics(y_val_sex, sex_val, weights, \"Sex_F\", thresh=t_sex)\n",
    "    scores_sex.append((sex_brier, sex_f1))\n",
    "\n",
    "    X_train.loc[:, \"sex_proba\"] = sex_train\n",
    "    X_val.loc[:, \"sex_proba\"] = sex_val\n",
    "\n",
    "    for interaction in interactions:\n",
    "        X_train.loc[:, f\"I_{interaction}\"] = X_train[interaction] * X_train[\"sex_proba\"]\n",
    "        X_val.loc[:, f\"I_{interaction}\"] = X_val[interaction] * X_val[\"sex_proba\"]\n",
    "\n",
    "    model_2, scores_adhd_gridcv = GridSearch(X_train[features_adhd], y_train_adhd, weights_train)\n",
    "    all_Bestmodels_adhd.append(model_2)\n",
    "    scores_adhd_gridcvs.append(scores_adhd_gridcv)\n",
    "\n",
    "    adhd_val = model_2.predict_proba(X_val[features_adhd])[:, 1]\n",
    "    adhd_oof[val_idx] += adhd_val / REPEATS\n",
    "\n",
    "    adhd_brier, adhd_f1 = eval_metrics(y_val_adhd, adhd_val, weights, \"Outcome ADHD\", thresh=t_adhd)\n",
    "    scores_adhd.append((adhd_brier, adhd_f1))\n",
    "\n",
    "print(f\"\\n=== CV Results ===\")\n",
    "print(f\"Sex Mean Brier Score: {np.mean([s[0] for s in scores_sex]):.4f}\")\n",
    "print(f\"Sex Mean F1: {np.mean([s[1] for s in scores_sex]):.4f}\")\n",
    "print(f\"ADHD Mean Brier Score: {np.mean([s[0] for s in scores_adhd]):.4f}\")\n",
    "print(f\"ADHD Mean F1: {np.mean([s[1] for s in scores_adhd]):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5d608185-e4b0-48fc-8449-43313e5e014a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sex Thresholds: 100%|███████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 181.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 25\n",
      "Best sex threshold: 0.15151515151515152\n",
      "Number of evaluated thresholds: 100\n",
      "Final best sex score: 0.6299287410926366\n",
      "Best model index for Sex: 6\n",
      "Best F1-score for Sex: 0.6666666666666666\n",
      "25 25\n",
      "Best model index for ADHD: 9\n",
      "Best F1-score for ADHD: 0.9071274298056156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# === 1. Find Best Threshold for Sex Based on OOF Probabilities ===\n",
    "weights = ((y_adhd == 1) & (y_sex == 1)) + 1  # Double weight if both ADHD and Sex == 1\n",
    "\n",
    "thresholds = np.linspace(0, 1, 100)\n",
    "sex_scores = []\n",
    "\n",
    "for t in tqdm(thresholds, desc=\"Sex Thresholds\"):\n",
    "    tmp_pred = np.where(sex_oof > t, 1, 0)\n",
    "    tmp_score = f1_score(y_sex, tmp_pred, sample_weight=weights)\n",
    "    sex_scores.append(tmp_score)\n",
    "\n",
    "best_sex_threshold = thresholds[np.argmax(sex_scores)]\n",
    "print(len(all_Bestmodels_sex),len(scores_sex))\n",
    "best_sex_score = max(sex_scores)\n",
    "\n",
    "print(\"Best sex threshold:\", best_sex_threshold)\n",
    "print(\"Number of evaluated thresholds:\", len(sex_scores))\n",
    "print(\"Final best sex score:\", best_sex_score)\n",
    "\n",
    "\n",
    "# === 2. Get Best Sex Model from CV ===\n",
    "f1_scores_sex = [score[1] for score in scores_sex]\n",
    "best_model_idx_sex = np.argmax(f1_scores_sex)\n",
    "best_model_sex = all_Bestmodels_sex[best_model_idx_sex]\n",
    "\n",
    "print(\"Best model index for Sex:\", best_model_idx_sex)\n",
    "print(\"Best F1-score for Sex:\", f1_scores_sex[best_model_idx_sex])\n",
    "\n",
    "\n",
    "# === 3. Get Best ADHD Model from CV ===\n",
    "f1_scores_adhd = [score[1] for score in scores_adhd]\n",
    "best_model_idx_adhd = np.argmax(f1_scores_adhd)\n",
    "print(len(all_Bestmodels_adhd),len(scores_adhd))\n",
    "best_model_adhd = all_Bestmodels_adhd[best_model_idx_adhd]\n",
    "\n",
    "print(\"Best model index for ADHD:\", best_model_idx_adhd)\n",
    "print(\"Best F1-score for ADHD:\", f1_scores_adhd[best_model_idx_adhd])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "88fda05d-5ac7-45ff-9992-b668894f3c86",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sex Thresholds: 100%|███████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 203.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best sex threshold: 0.15151515151515152\n",
      "Number of evaluated thresholds: 100\n",
      "Final best sex score: 0.6299287410926366\n",
      "Best threshold index for Sex: 6\n",
      "Best F1-score for Sex: 0.6666666666666666\n",
      "Best threshold index for ADHD: 8\n",
      "Best F1-score for ADHD: 0.8750552685364517\n",
      "Best threshold for ADHD: 0.1627193137276046\n",
      "Best Model for ADHD: Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('clf',\n",
      "                 XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, device=None,\n",
      "                               early_stopping_rounds=None,\n",
      "                               enable_categorical=False, eval_metric='logloss',\n",
      "                               feature_types=None, feature_weights=None,\n",
      "                               gamma=None, grow_policy=None,\n",
      "                               importance_type=None,\n",
      "                               interaction_constraints=None, learning_rate=0.07,\n",
      "                               max_bin=None, max_cat_threshold=None,\n",
      "                               max_cat_to_onehot=None, max_delta_step=None,\n",
      "                               max_depth=5, max_leaves=None,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, multi_strategy=None,\n",
      "                               n_estimators=50, n_jobs=None,\n",
      "                               num_parallel_tree=None, ...))])\n"
     ]
    }
   ],
   "source": [
    "# Compute weighted F1-scores to find best threshold for sex\n",
    "weights = ((y_adhd == 1) & (y_sex == 1)) + 1\n",
    "thresholds = np.linspace(0, 1, 100)\n",
    "sex_scores = []\n",
    "for t in tqdm(thresholds, desc=\"Sex Thresholds\"):\n",
    "    tmp_pred = np.where(sex_oof > t, 1, 0)\n",
    "    tmp_score = f1_score(y_sex, tmp_pred, sample_weight=weights)\n",
    "    sex_scores.append(tmp_score)\n",
    "\n",
    "best_sex_threshold = thresholds[np.argmax(sex_scores)]\n",
    "best_sex_score = max(sex_scores)\n",
    "\n",
    "print(\"Best sex threshold:\", best_sex_threshold)\n",
    "print(\"Number of evaluated thresholds:\", len(sex_scores))\n",
    "print(\"Final best sex score:\", best_sex_score)\n",
    "\n",
    "# Ensure 'scores_sex' contains tuples (threshold, F1-score)\n",
    "# print(\"Scores for sex grid CV:\", scores_sex)\n",
    "f1_scores_sex = [score[1] for score in scores_sex]\n",
    "\n",
    "best_model_idx_sex = np.argmax(f1_scores_sex)\n",
    "print(\"Best threshold index for Sex:\", best_model_idx_sex)\n",
    "print(\"Best F1-score for Sex:\", f1_scores_sex[best_model_idx_sex])\n",
    "# print(\"Best threshold for Sex:\", scores_sex[best_model_idx_sex][0])\n",
    "\n",
    "best_model_sex = all_Bestmodels_sex[best_model_idx_sex]\n",
    "# print(\"Best model for Sex:\", best_model_sex)\n",
    "# print(\"Scores for ADHD grid CV:\", scores_adhd)\n",
    "f1_scores_adhd = [score[1] for score in scores_adhd]\n",
    "\n",
    "best_model_idx_adhd = np.argmax(scores_adhd_gridcvs)\n",
    "print(\"Best threshold index for ADHD:\", best_model_idx_adhd)\n",
    "print(\"Best F1-score for ADHD:\", scores_adhd_gridcvs[best_model_idx_adhd])\n",
    "print(\"Best threshold for ADHD:\", scores_adhd[best_model_idx_adhd][0])\n",
    "\n",
    "best_model_adhd = all_Bestmodels_adhd[best_model_idx_adhd]\n",
    "print(\"Best Model for ADHD:\" , best_model_adhd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0007e7d8-a419-480c-a077-d2354b08b9ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ADHD Thresholds: 100%|██████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 212.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " best_adhd_threshold :  0.38383838383838387\n",
      "Final Best_ADHD_score 0.8853855986365573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "adhd_scores = []\n",
    "for t in tqdm(thresholds, desc=\"ADHD Thresholds\"):\n",
    "    tmp_pred = np.where(adhd_oof > t, 1, 0)\n",
    "    tmp_score = f1_score(y_adhd, tmp_pred, sample_weight=weights)\n",
    "    adhd_scores.append(tmp_score)\n",
    "best_adhd_threshold = thresholds[np.argmax(adhd_scores)]\n",
    "best_adhd_score = max(adhd_scores)\n",
    "\n",
    "print( \" best_adhd_threshold : \" , best_adhd_threshold)\n",
    "\n",
    "print( \"Final Best_ADHD_score\", best_adhd_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "16324a99-b1c2-44c5-acca-595c788d17ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_sex.fit(train_combined[features_sex], y_sex, clf__sample_weight=weights)\n",
    "sex_proba_train = best_model_sex.predict_proba(train_combined[features_sex])[:,1]\n",
    "sex_proba_test = best_model_sex.predict_proba(test_combined[features_sex])[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3ccf9ee9-a390-4d84-bfc5-5f77bb08d222",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_combined[\"sex_proba\"] = sex_proba_train\n",
    "test_combined[\"sex_proba\"] = sex_proba_test\n",
    "for interaction in interactions:\n",
    "    train_combined[f\"I_{interaction}\"] = train_combined[\"sex_proba\"] * train_combined[interaction]\n",
    "    test_combined[f\"I_{interaction}\"] = test_combined[\"sex_proba\"] * test_combined[interaction]\n",
    "best_model_adhd.fit(train_combined[features_adhd], y_adhd, clf__sample_weight=weights)\n",
    "adhd_proba_test = best_model_adhd.predict_proba(test_combined[features_adhd])[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0019179b-6574-4284-b015-6c0daa6501fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_excel(\"./SAMPLE_SUBMISSION.xlsx\")\n",
    "submission[\"ADHD_Outcome\"] = np.where(adhd_proba_test > best_adhd_threshold, 1, 0)\n",
    "submission[\"Sex_F\"] = np.where(sex_proba_test > best_sex_threshold, 1, 0)\n",
    "submission.to_csv(\"submission__trial_3.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcace258-0c27-407a-a2fe-8f1e4c134d32",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
